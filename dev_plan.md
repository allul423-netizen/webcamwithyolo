

------

## 📋 “新宿街头 AI 脑”项目开发计划书

### 1. 需求明确 (Core Features)

- **实时流解析**：稳定抓取 YouTube 新宿大路口的直播信号。
- **本地快速识别**：在不依赖 GPU 的情况下，利用 YOLOv8n 实时统计画面中的行人、车辆和信号灯。
- **双脑协同对话**：
  - **左脑（本地）**：提供高频的数值统计（如“当前有 15 辆车”）。
  - **右脑（云端）**：通过 Qwen2-VL 大模型理解复杂意图（如“现在交通拥堵吗？”、“天气如何？”）。
- **交互式看板**：使用 Streamlit 搭建一个左侧看直播、右侧聊天的 Web 界面。

------

### 2. 解决方案 (System Workflow)

1. **数据采集层**：`yt-dlp` 负责把网页链接解析成视频流地址，`OpenCV` 负责“接水”一样把画面一帧帧存入内存。
2. **异步处理层 (关键优化)**：
   - **线程 A**：专门负责抓取最新帧并清空旧缓存，保证视频不延迟。
   - **线程 B**：每隔 0.5 秒从线程 A 拿一张图给 YOLO 识别，并更新统计数据。
3. **展示与交互层**：Streamlit 负责把最新的画面和统计结果刷在网页上。当用户提问时，它会瞬间“抓拍”当前画面发给云端 AI。

------

### 3. 技术栈选型与功能映射

为了让你听得懂，我用**“餐厅”**来做类比：

| **技术组件**               | **角色 (类比)** | **实际作用**                                           |
| -------------------------- | --------------- | ------------------------------------------------------ |
| **Python**                 | **主厨**        | 整个项目的核心逻辑驱动。                               |
| **yt-dlp**                 | **采购员**      | 负责去 YouTube 把原始的视频素材“买”回来。              |
| **OpenCV**                 | **案板师傅**    | 负责切分视频帧，并在画面上“雕花”（画检测框）。         |
| **YOLOv8n**                | **前台计数员**  | 反应极快，一眼就能数清有多少客人（车/人）。            |
| **Streamlit**              | **餐厅装修**    | 无需懂复杂装修（HTML），用 Python 就能搭出漂亮的店面。 |
| **SiliconFlow (Qwen2-VL)** | **总店专家**    | 遇到复杂问题时，通过电话（API）远程请教的高级专家。    |
| **Dotenv**                 | **保险柜**      | 存放 API Key 等秘密文件，不让外人看见。                |

------

### 4. 潜在风险与对策

- **网络断流**：直播流可能因为网络原因中断。
  - *对策*：代码中加入 `try-except` 自动重连机制。
- **CPU 过载**：如果 YOLO 跑得太频繁，电脑会发烫卡顿。
  - *对策*：采用**“跳帧检测”**策略（每 15 帧检测一次）。
- **API 响应延迟**：云端大模型思考需要 2-5 秒。
  - *对策*：在界面上添加 Loading 动画，提升用户体验。

------

### 5. 实施步骤 (Roadmap)

1. **Step 0**: 环境准备（安装 Python、创建虚拟环境、配置 `.env`）。
2. **Step 1**: 编写“视频抓取脚本”，确保能在本地窗口看到直播流。
3. **Step 2**: 接入 YOLO 模块，实现“边看边数数”。
4. **Step 3**: 搭建 Streamlit 基础界面。
5. **Step 4**: 接入 SiliconFlow API，完成“识图说话”功能。

------

**以上计划是否清晰？我们可以开始编写第一阶段的代码（环境配置与视频流抓取）了吗？**